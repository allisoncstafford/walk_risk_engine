{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from model2 import *\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql_query(\"\"\"\n",
    "                        SELECT latitude, \n",
    "                                longitude, \n",
    "                                ap_t_high100, \n",
    "                                n_arrests\n",
    "                        FROM manhattan_loc_d_ar_wea \n",
    "                        ;\"\"\"\n",
    "                        , 'postgresql:///walk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorized_df = categorize_arrests(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # add combined lat/long location feature\n",
    "    categorized_df['latlong'] = (categorized_df['latitude'].astype(str) \n",
    "                                + categorized_df['longitude'].astype(str))\n",
    "    X_train, y_train, X_eval, y_eval = split_last(categorized_df, target_col='n_arrests',\n",
    "                                                  sort_col=None, cut=.8)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nieve Log Loss as baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.zeros(y_train.shape)\n",
    "preds[0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_train, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest w/ OneHotEncoded latlong, latitude, longitude, daily high temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = ColumnTransformer( \n",
    "    transformers=[\n",
    "    ('ohe', OneHotEncoder(categories='auto'), ['latlong']),\n",
    "    ('ss', 'passthrough', ['latitude', 'longitude', 'ap_t_high100']),\n",
    "    ], remainder='drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, max_depth=20,\n",
    "                            class_weight='balanced', max_features=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocessor', column_transformer),\n",
    "    ('model', rfc)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_loss_cvs(pipe, X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation w/ temp, lat/long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessor',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories='auto',\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                n_values=None,\n",
       "                                                                sparse=True),\n",
       "                                                  ['latlong']),\n",
       "                                                 ('ss', 'passthrough',\n",
       "                                                  ['latitude',...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
       "                                        criterion='gini', max_depth=20,\n",
       "                                        max_features=2000, max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_probas = pipe.predict_proba(X_train)\n",
    "test_probas = pipe.predict_proba(X_eval)\n",
    "test_predict = pipe.predict(X_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training log loss: 0.44835417606880607\n",
      "test neg log loss: 0.4555676287549664\n",
      "confusion matrix: \n",
      "[[518571 158280]\n",
      " [  3275   7882]]\n",
      "accuracy: 0.7651844164602737\n",
      "F1: 0.08890192252381303\n"
     ]
    }
   ],
   "source": [
    "print(f\"training log loss: {log_loss(y_train, train_probas)}\") \n",
    "print(f\"test neg log loss: {log_loss(y_eval, test_probas)}\")\n",
    "print(f\"confusion matrix: \\n{confusion_matrix(y_eval, test_predict)}\")\n",
    "print(f\"accuracy: {accuracy_score(y_eval, test_predict)}\")\n",
    "print(f\"F1: {f1_score(y_eval, test_predict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib_pipeline(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (geo-env)",
   "language": "python",
   "name": "geo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
